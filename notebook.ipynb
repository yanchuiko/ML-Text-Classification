{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Core Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (This is News_Categories.csv, I renamed it to dataset.csv for simplicity)\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last 5 rows of the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows and Columns of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null Values\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns: authors, link, date\n",
    "df = df.drop(['authors', 'link', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge headline and short_description into one column called 'text'\n",
    "df['text'] = df['headline'] + ' ' + df['short_description']\n",
    "\n",
    "# Drop headline and short_description columns because they are no longer needed\n",
    "df = df.drop(['headline', 'short_description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique categories\n",
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of unique categories\n",
    "df['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of culture and arts categories\n",
    "culture_arts_categories = ['ARTS', 'CULTURE & ARTS', 'ARTS & CULTURE']\n",
    "\n",
    "# Array of news categories\n",
    "news_categories = ['WEIRD NEWS', 'WORLD NEWS', 'GOOD NEWS']\n",
    "\n",
    "# Array of voices categories\n",
    "voices_categories = ['LATINO VOICES', 'BLACK VOICES', 'QUEER VOICES']\n",
    "\n",
    "# Bundle the culture and arts categories into one category called 'CULTURE & ARTS'\n",
    "df['category'] = df['category'].replace(culture_arts_categories, 'CULTURE & ARTS')\n",
    "\n",
    "# Bundle the news categories into one category called 'NEWS'\n",
    "df['category'] = df['category'].replace(news_categories, 'NEWS')\n",
    "\n",
    "# Bundle the voices categories into one category called 'VOICES'\n",
    "df['category'] = df['category'].replace(voices_categories, 'VOICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categories with the same or similar meaning\n",
    "df['category'] = df['category'].replace('STYLE & BEAUTY', 'STYLE')\n",
    "df['category'] = df['category'].replace('PARENTING', 'PARENTS')\n",
    "df['category'] = df['category'].replace('COLLEGE', 'EDUCATION')\n",
    "df['category'] = df['category'].replace('TASTE', 'FOOD & DRINK')\n",
    "df['category'] = df['category'].replace('DIVORCE', 'WEDDINGS')\n",
    "df['category'] = df['category'].replace('MONEY', 'BUSINESS')\n",
    "df['category'] = df['category'].replace('HEALTHY LIVING', 'WELLNESS')\n",
    "df['category'] = df['category'].replace('THE WORLDPOST', 'WORLDPOST')\n",
    "df['category'] = df['category'].replace('WORLDPOST', 'NEWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop trash categories\n",
    "trash_categories = ['GREEN', 'FIFTY']\n",
    "df = df[~df['category'].isin(trash_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique categories\n",
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of unique categories\n",
    "df['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the count of each category before Downsampling\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(df['category'])\n",
    "plt.title('Count of Each Category before Downsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate the dataset into different categories\n",
    "politics = df[df['category'] == 'POLITICS']\n",
    "wellness = df[df['category'] == 'WELLNESS']\n",
    "entertainment = df[df['category'] == 'ENTERTAINMENT']\n",
    "other_categories = df[(df['category'] != 'POLITICS') & \n",
    "                      (df['category'] != 'WELLNESS') & \n",
    "                      (df['category'] != 'ENTERTAINMENT')]\n",
    "\n",
    "# Downsample the categories with more than 10000 samples\n",
    "politics = resample(politics, replace=False, n_samples=10000, random_state=42)\n",
    "wellness = resample(wellness, replace=False, n_samples=10000, random_state=42)\n",
    "entertainment = resample(entertainment, replace=False, n_samples=10000, random_state=42)\n",
    "\n",
    "# Combine the downsampled categories back into a single dataframe\n",
    "df_downsampled = pd.concat([politics, wellness, entertainment])\n",
    "\n",
    "# Merge the downsampled dataframe with the dataframe of other categories\n",
    "df = pd.concat([other_categories, df_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the count of each category after downsampling\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(df['category'])\n",
    "plt.title('Count of Each Category After Downsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples in each category\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "# Get a list of categories that have less than 6000 samples\n",
    "categories_to_drop = category_counts[category_counts < 6000].index\n",
    "\n",
    "# Drop these categories from the dataframe\n",
    "df = df[~df['category'].isin(categories_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the count of each category after dropping categories with less than 6000 samples\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(df['category'])\n",
    "plt.title('Count of Each Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from langdetect import detect\n",
    "\n",
    "# Function to detect the language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "    \n",
    "# Apply the function to the 'text' column\n",
    "df['language'] = df['text'].apply(detect_language)\n",
    "\n",
    "# Drop the rows where the language is not English\n",
    "df = df[df['language'] == 'en']\n",
    "\n",
    "# Drop the 'language' column\n",
    "df = df.drop('language', axis=1)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Function that Normalizes my 'text' column\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace all diacritical marks with their corresponding characters\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove URLs    \n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    \n",
    "    # Remove new line characters\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    \n",
    "    # Remove punctuation and underscores\n",
    "    text = re.sub(r'[^\\w\\s]|_', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return text\n",
    "\n",
    "# Here I apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to lemmatize the text\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the lemmatize_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "\n",
    "# Display the updated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and Y\n",
    "X = df['text'] # Feature\n",
    "Y = df['category'] # Target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_bow = cv.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_bow = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tv = tv.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tv = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing Vectorization\n",
    "\n",
    "# Initialize the HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2**20, alternate_sign=False)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_hv = hv.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_hv = hv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes Classifier\n",
    "nb_bow = MultinomialNB()\n",
    "nb_tv = MultinomialNB()\n",
    "nb_hv = MultinomialNB()\n",
    "\n",
    "# Train the models\n",
    "nb_bow.fit(X_train_bow, Y_train)\n",
    "nb_tv.fit(X_train_tv, Y_train)\n",
    "nb_hv.fit(X_train_hv, Y_train)\n",
    "\n",
    "# Predictions using Naive Bayes Classifier\n",
    "Y_pred_nb_bow = nb_bow.predict(X_test_bow)\n",
    "Y_pred_nb_tv = nb_tv.predict(X_test_tv)\n",
    "Y_pred_nb_hv = nb_hv.predict(X_test_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression Classifier\n",
    "lr_bow = LogisticRegression(max_iter=1000)\n",
    "lr_tv = LogisticRegression(max_iter=1000)\n",
    "lr_hv = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the models\n",
    "lr_bow.fit(X_train_bow, Y_train)\n",
    "lr_tv.fit(X_train_tv, Y_train)\n",
    "lr_hv.fit(X_train_hv, Y_train)\n",
    "\n",
    "# Predictions using Logistic Regression Classifier\n",
    "Y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "Y_pred_lr_tv = lr_tv.predict(X_test_tv)\n",
    "Y_pred_lr_hv = lr_hv.predict(X_test_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize the Linear SVM Classifier\n",
    "svm_bow = LinearSVC()\n",
    "svm_tv = LinearSVC()\n",
    "svm_hv = LinearSVC()\n",
    "\n",
    "# Train the models\n",
    "svm_bow.fit(X_train_bow, Y_train)\n",
    "svm_tv.fit(X_train_tv, Y_train)\n",
    "svm_hv.fit(X_train_hv, Y_train)\n",
    "\n",
    "# Predictions using SVM Classifier\n",
    "Y_pred_svm_bow = svm_bow.predict(X_test_bow)\n",
    "Y_pred_svm_tv = svm_tv.predict(X_test_tv)\n",
    "Y_pred_svm_hv = svm_hv.predict(X_test_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def report(Y_test, Y_pred):\n",
    "    print('\\nClassification Report:\\n', classification_report(Y_test, Y_pred))\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "def validation(model, X, Y):\n",
    "    accuracy = cross_val_score(model, X, Y, cv=5, scoring='accuracy')\n",
    "    print('Cross Validation Accuracy:', accuracy.mean())\n",
    "\n",
    "def plot(Y_test, Y_pred):\n",
    "    categories = df['category'].unique()\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluation(model, X_train, Y_train, Y_test, Y_pred, vectorizer_name):\n",
    "    print(f'\\nModel using {vectorizer_name}:')\n",
    "    report(Y_test, Y_pred)\n",
    "    validation(model, X_train, Y_train)\n",
    "    plot(Y_test, Y_pred)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NAIVE BAYES')\n",
    "evaluation(nb_bow, X_train_bow, Y_train, Y_test, Y_pred_nb_bow, 'BoW')\n",
    "evaluation(nb_tv, X_train_tv, Y_train, Y_test, Y_pred_nb_tv, 'TF-IDF')\n",
    "evaluation(nb_hv, X_train_hv, Y_train, Y_test,Y_pred_nb_hv, 'Hashing Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOGISTIC REGRESSION')\n",
    "evaluation(lr_bow, X_train_bow, Y_train, Y_test, Y_pred_lr_bow, 'BoW')\n",
    "evaluation(lr_tv, X_train_tv, Y_train, Y_test, Y_pred_lr_tv, 'TF-IDF')\n",
    "evaluation(lr_hv, X_train_hv, Y_train, Y_test, Y_pred_lr_hv, 'Hashing Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM')\n",
    "evaluation(svm_bow, X_train_bow, Y_train, Y_test, Y_pred_svm_bow, 'BoW')\n",
    "evaluation(svm_tv, X_train_tv, Y_train, Y_test, Y_pred_svm_tv, 'TF-IDF')\n",
    "evaluation(svm_hv, X_train_hv, Y_train, Y_test, Y_pred_svm_hv, 'Hashing Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization_results = {\n",
    "    'Naive Bayes BoW': accuracy_score(Y_test, Y_pred_nb_bow),\n",
    "    'Naive Bayes TF-IDF': accuracy_score(Y_test, Y_pred_nb_tv),\n",
    "    'Naive Bayes Hashing Vectorizer': accuracy_score(Y_test, Y_pred_nb_hv),\n",
    "    'Logistic Regression BoW': accuracy_score(Y_test, Y_pred_lr_bow),\n",
    "    'Logistic Regression TF-IDF': accuracy_score(Y_test, Y_pred_lr_tv),\n",
    "    'Logistic Regression Hashing Vectorizer': accuracy_score(Y_test, Y_pred_lr_hv),\n",
    "    'SVM BoW': accuracy_score(Y_test, Y_pred_svm_bow),\n",
    "    'SVM TF-IDF': accuracy_score(Y_test, Y_pred_svm_tv),\n",
    "    'SVM Hashing Vectorizer': accuracy_score(Y_test, Y_pred_svm_hv)\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(vectorization_results.keys(), vectorization_results.values())\n",
    "plt.title('Vectorization Results')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "for key, value in vectorization_results.items():\n",
    "    plt.text(key, value, f'{value:.2f}', ha='center')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
